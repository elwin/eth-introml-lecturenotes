\section{Generative Adversarial Networks}
The previously considered generative models
were very simple and fail to capture high-dimensional,
complex data such as audio or images.
Thus, the goal is to use neural networks
for generative modelling.

Given a sample $\vec{x}_1, \dotsc, \vec{x}_n$,
\emph{implicit generative models} are models
of the form
\begin{equation*}
    \vec{X} = G(\vec{Z}; \vec{w})
\end{equation*}
where $\vec{Z}$ is a simple distribution
(e.g. low-dimensional Gaussian),
$G$ is a flexible non-linear mapping
(e.g. neural network)
and $\vec{X}$ is the data-generating process.

The key challenge with implicit generative models
is to compute the data likelihood,
which is generally not possible.
If we start with a simple distribution
and know $P(z)$, what is $P(\vec{x})$?
This not only depends on the prior but
also on the parameters.
The distribution is very complicated,
intractable in general,
and therefore the maximum likelihood
cannot just be calculated as usual.
Thus, surrogate objective functions
are required for training.
This leads to
\emph{Variational Autoencoders} (VAEs)
and \emph{Generative Adversarial Networks} (GANs).

\subsection{Formulation}
The key idea is to optimise the parameters
such that the samples from the model are
hard to distinguish from the real data samples.
Distinguishing is a classification problem,
thus a discriminator network is trained to do so.
This is called \emph{discriminative learning}.

Now, two neural networks are trained simultaneously.
The \emph{generator} network $G : \mathbb{R}^m \to \mathbb{R}^d$
tries to generate realistic examples;
the \emph{discriminator} network
$D : \mathbb{R}^d \to [0, 1]$
tries to distinguish real and generated samples.

The discriminator wants
\begin{equation*}
    D(\vec{x}) =
    \begin{cases}
        \approx 1 & \text{if $x$ is real} \\
        \approx 0 & \text{if $x$ is generated}
    \end{cases}
\end{equation*}
The generator wants
\begin{equation*}
    D(G(\vec{z})) \approx 1 \text{ for samples $\vec{z}$}
\end{equation*}
This results in the following \emph{minimax} game:
\begin{equation*}
    \min_G{\max_D{
        \mathbb{E}_{\vec{x} \sim \text{Data}}[\log{D(\vec{x})}]
        +
        \mathbb{E}_{\vec{z} \sim \vec{Z}}[\log{(1 - D(G(\vec{z}))}]
    }}
\end{equation*}
Here, the logarithm was used,
but there are other monotonic
transformations used.


\subsection{Training}
The original objective optimises over
$G$ and $D$ directly.
However, we want to fix the function class
(i.e. neural network architecture)
and optimise over weights:
\begin{equation*}
    \min_{\vec{w}_G}{\max_{\vec{w}_D}{
    \underbrace{
        \mathbb{E}_{\vec{x} \sim \text{Data}}[\log{D(\vec{x}; \vec{w}_D)}]
        +
        \mathbb{E}_{\vec{z} \sim \vec{Z}}[\log{(1 - D(G(\vec{z}; \vec{w}_G); \vec{w}_D)}]
    }_{M(\vec{w}_G, \vec{w}_D)}
    }}
\end{equation*}

From the conflicting objective,
optimising
\begin{equation*}
    \min_{\vec{w}_G}{\max_{\vec{w}_D}{
    M(\vec{w}_G, \vec{w}_D)
    }}
\end{equation*}
requires finding a \emph{saddle point}
rather than a minimum.

If $G$ and $D$ have enough capacity,
the data-generating distribution is
actually a saddle point of
$\min_{\vec{w}_G}{\max_{\vec{w}_D}{M(\vec{w}_G, \vec{w}_D)}}$.
This is because
$\max_{\vec{w}_G}{M(\vec{w}_G, \vec{w}_D)}$ is
up to constants the Jensen-Shannon divergence
$JS(P_\text{Data} || P_G)$.

The \emph{Jensen-Shannon divergence} between
two distributions $p, q$ is defined as
\begin{equation*}
    JS(p || q) =
    \frac{1}{2} KL(p || \frac{p+q}{2})
    +
    \frac{1}{2} KL(q || \frac{p+q}{2})
\end{equation*}
and is sort-of a symmetric version
of the KL-divergence.
It holds (under some restrictions) that
$JS(p || q) = 0 \Leftrightarrow p = q$.

Commonly, (mini-batch) SGD is applied to
the generator and discriminator simultaneously:
\begin{align*}
    \vec{w}_G^{(t+1)} &= \vec{w}_G^{(t)} - \eta_t \nabla_{\vec{w}_G} M(\vec{w}_G, \vec{w}_D^{(t)}) \\
    \vec{w}_D^{(t+1)} &= \vec{w}_D^{(t)} + \eta_t \nabla_{\vec{w}_D} M(\vec{w}_G^{(t)}, \vec{w}_D) \\
\end{align*}
where the different signs indicate the difference
of minimising/maximising.
There are also other variants where the
networks are updated sequentially.


\subsection{Challenges}
GANs are notoriously hard to train,
and many tricks/heuristics exist to
mitigate some problems.

\subsubsection{Oscillations / Divergence}
Because two conflicting objectives are optimised,
it might happen that the weights oscillate
around a local minimum or even diverge.

\subsubsection{Mode Collapse}
It might happen that the generator models
certain modes of the data well
but completely ignores others.

This can happen if the discriminator
cannot detect that only samples from
a certain mode are generated.
It might also happen that the
well-modelled modes switch as
soon as the discriminator has adjusted.

\subsubsection{Data Memorisation}
The GAN objective is similar to minimising
a JS-divergence.
In practice,
if the JS divergence of the sample data
would be minimised,
the optimal generator would just
uniformly sample from the data set.

Thus, the model is prone to memorising
the data set instead of actually learning the distribution.
By going away from the idealised setting,
i.e. making restricting the discriminator capacity,
we get better samples.

\subsubsection{Evaluation}
Evaluating GANs is currently an unresolved issue.
Because the likelihood is intractable,
it cannot be calculated on a holdout set.

There exist various heuristics,
but no domain-independent solutions.
